{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL \n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "CONFIDENTIAL AND PROPRIETARY\n",
    "\n",
    "*COPYRIGHT Â© [2025] [Radu-Constantin Flesar][Sebastian-Aurelian Stefaniga]*\n",
    "\n",
    "*ALL RIGHTS RESERVED. UNAUTHORIZED COPYING*\n",
    "\n",
    "\n",
    "*REPRODUCTION, OR DISTRIBUTION OF THIS*\n",
    "\n",
    "\n",
    "*CODE, IN WHOLE OR IN PART, IS STRICTLY*\n",
    "\n",
    "*PROHIBITED WITHOUT PRIOR WRITTEN PERMISSION FROM THE AUTHORS:*\n",
    "\n",
    "\n",
    "Flesar Radu-Constantin (radu.flesar02@e-uvt.ro)\n",
    "\n",
    "\n",
    "Sebastian-Aurelian Stefaniga (sebastian.stefaniga@e-uvt.ro)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 875 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Initialize the ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the images from the directory\n",
    "folder_path = \"./Data2/\"\n",
    "image_dataset = datagen.flow_from_directory(\n",
    "    directory=folder_path,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bolnav': 0, 'Sanatos': 1}\n"
     ]
    }
   ],
   "source": [
    "print(image_dataset.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(32 * 32 * 256, input_dim=100))\n",
    "    model.add(layers.Reshape((32, 32, 256)))\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(0.3))\n",
    "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(0.3))\n",
    "    model.add(layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(0.3))\n",
    "    model.add(layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh'))\n",
    "    return model\n",
    "\n",
    " \n",
    "\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32, (4, 4), strides=(2, 2), padding='same', input_shape=(512, 512, 3)))\n",
    "    model.add(layers.LeakyReLU(0.3))\n",
    "    model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(0.3))\n",
    "    model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(0.3))\n",
    "    model.add(layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "generator = build_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 262144)            26476544  \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2D  (None, 64, 64, 128)       524416    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2D  (None, 128, 128, 64)      131136    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2D  (None, 256, 256, 32)      32800     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 256, 256, 32)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2D  (None, 512, 512, 3)       1539      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27166435 (103.63 MB)\n",
      "Trainable params: 27166435 (103.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 256, 256, 32)      1568      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 256, 256, 32)      0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 128, 128, 64)      32832     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 64, 64, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 256)       524544    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 262144)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 262145    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 952289 (3.63 MB)\n",
      "Trainable params: 952289 (3.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = keras.optimizers.legacy.Adam(learning_rate=0.00001) \n",
    "d_opt = keras.optimizers.legacy.Adam(learning_rate=0.00001) \n",
    "g_loss = keras.losses.BinaryCrossentropy()\n",
    "d_loss = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(Model): \n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.generator = generator \n",
    "        self.discriminator = discriminator \n",
    "        \n",
    "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs): \n",
    "        super().compile(*args, **kwargs)\n",
    "    \n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss \n",
    "    \n",
    "        #self.outputs = [self.generator.outputs[0], self.discriminator.outputs[0]]\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        real_images, _ = batch\n",
    "        tf.random.set_seed(datetime.now().microsecond)\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        fake_images = self.generator(tf.random.normal([16, 100]), training=False)\n",
    "        \n",
    "        with tf.GradientTape() as d_tape: \n",
    "            yhat_real = self.discriminator(real_images, training=True) \n",
    "            yhat_fake = self.discriminator(fake_images, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "            \n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "            \n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "            \n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "            \n",
    "        # Backpropagation\n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables) \n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "        \n",
    "        with tf.GradientTape() as g_tape: \n",
    "            gen_images = self.generator(tf.random.normal([16, 100]), training=True)\n",
    "                                        \n",
    "            predicted_labels = self.discriminator(gen_images, training=False)\n",
    "                                        \n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels) \n",
    "            \n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}\n",
    "    \n",
    "    def fitt(self, data, epochs=1, verbose=1):\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            for i, batch in enumerate(data):\n",
    "                result = self.train_step(batch)\n",
    "                if verbose and i % 100 == 0:\n",
    "                    print(f\"Step {i}: discriminator loss = {result['d_loss']}, generator loss = {result['g_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(g_opt, d_opt, g_loss, d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=2, latent_dim=100):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim))\n",
    "        generated_images = generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i]) \n",
    "            path = os.path.join('/Users/raduflesar/Documents/Gait/images/', f'generated_img_{epoch}_{i}.png')\n",
    "            img.save(path)\n",
    "\n",
    "        # Save model every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            generator.save(os.path.join('/Users/raduflesar/Documents/Gait/Models/', f'generator_{epoch}.h5'))\n",
    "            discriminator.save((os.path.join('/Users/raduflesar/Documents/Gait/Models/', f'discriminator_{epoch}.h5')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241m.\u001b[39mfit(image_dataset, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40000\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[ModelMonitor()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gan' is not defined"
     ]
    }
   ],
   "source": [
    "model = gan.fit(image_dataset, epochs=40000, callbacks=[ModelMonitor()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
