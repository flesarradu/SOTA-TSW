{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL \n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "CONFIDENTIAL AND PROPRIETARY\n",
    "\n",
    "*COPYRIGHT Â© [2025] [Radu-Constantin Flesar]*\n",
    "\n",
    "*ALL RIGHTS RESERVED. UNAUTHORIZED COPYING*\n",
    "\n",
    "\n",
    "*REPRODUCTION, OR DISTRIBUTION OF THIS*\n",
    "\n",
    "\n",
    "*CODE, IN WHOLE OR IN PART, IS STRICTLY*\n",
    "\n",
    "*PROHIBITED WITHOUT PRIOR WRITTEN PERMISSION FROM THE AUTHORS:*\n",
    "\n",
    "\n",
    "Flesar Radu-Constantin (radu.flesar02@e-uvt.ro)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Initialize the ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the images from the directory\n",
    "folder_path = \"./DataCT/\"\n",
    "image_dataset = datagen.flow_from_directory(\n",
    "    directory=folder_path,\n",
    "    target_size=(512, 512),\n",
    "    batch_size=32\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_dataset.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(64 * 64 * 512, input_dim=100))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Reshape((64, 64, 512)))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='tanh'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(512, 512, 3)))\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 03:18:43.628141: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2025-02-17 03:18:43.628184: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2025-02-17 03:18:43.628191: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2025-02-17 03:18:43.628263: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-02-17 03:18:43.628313: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator()\n",
    "generator = build_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 2097152)           211812352 \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 2097152)           8388608   \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 2097152)           0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 128, 128, 256)     3277056   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 128, 128, 256)     1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 128, 128, 256)     0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 256, 256, 128)     819328    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 256, 256, 128)     512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 256, 256, 128)     0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 512, 512, 64)      204864    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 512, 512, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 512, 512, 64)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  (None, 1024, 1024, 3)     4803      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 224508803 (856.43 MB)\n",
      "Trainable params: 220313603 (840.43 MB)\n",
      "Non-trainable params: 4195200 (16.00 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 64)      4864      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 128)     204928    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128, 128, 128)     512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64, 64, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 512)       3277312   \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32, 32, 512)       2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 524288)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 524289    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4834433 (18.44 MB)\n",
      "Trainable params: 4832641 (18.44 MB)\n",
      "Non-trainable params: 1792 (7.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = keras.optimizers.legacy.Adam(learning_rate=0.00001) \n",
    "d_opt = keras.optimizers.legacy.Adam(learning_rate=0.00001) \n",
    "g_loss = keras.losses.BinaryCrossentropy()\n",
    "d_loss = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(Model): \n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.generator = generator \n",
    "        self.discriminator = discriminator \n",
    "        \n",
    "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs): \n",
    "        super().compile(*args, **kwargs)\n",
    "    \n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss \n",
    "\n",
    "    def train_step(self, batch):\n",
    "        real_images, _ = batch\n",
    "        tf.random.set_seed(datetime.now().microsecond)\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        fake_images = self.generator(tf.random.normal([32, 100]), training=False)\n",
    "        \n",
    "        with tf.GradientTape() as d_tape: \n",
    "            yhat_real = self.discriminator(real_images, training=True) \n",
    "            yhat_fake = self.discriminator(fake_images, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "            \n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "            \n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "            \n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "            \n",
    "        # Backpropagation\n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables) \n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "        \n",
    "        with tf.GradientTape() as g_tape: \n",
    "            gen_images = self.generator(tf.random.normal([32, 100]), training=True)\n",
    "                                        \n",
    "            predicted_labels = self.discriminator(gen_images, training=False)\n",
    "                                        \n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels) \n",
    "            \n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}\n",
    "    \n",
    "    def fitt(self, data, epochs=1, verbose=1):\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            for i, batch in enumerate(data):\n",
    "                result = self.train_step(batch)\n",
    "                if verbose and i % 100 == 0:\n",
    "                    print(f\"Step {i}: discriminator loss = {result['d_loss']}, generator loss = {result['g_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(g_opt, d_opt, g_loss, d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=2, latent_dim=100):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim))\n",
    "        generated_images = generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i]) \n",
    "            path = os.path.join('/Users/raduflesar/Documents/CTs/images/', f'generated_img_{epoch}_{i}.png')\n",
    "            img.save(path)\n",
    "\n",
    "        # Save model every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            generator.save(os.path.join('/Users/raduflesar/Documents/CTs/Models/', f'generator_{epoch}.h5'))\n",
    "            discriminator.save((os.path.join('/Users/raduflesar/Documents/CTs/Models/', f'discriminator_{epoch}.h5')))\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=500,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = gan.fit(image_dataset, epochs=40000, callbacks=[ModelMonitor(), early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
